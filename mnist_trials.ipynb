{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "y19fgSB2lCsu",
    "outputId": "680cefb9-58a3-45f5-ff02-a69e678fdd24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchdiffeq in /usr/local/lib/python3.6/dist-packages (0.0.1)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from torchdiffeq) (1.4.0)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from time import time\n",
    "from progressbar import progressbar\n",
    "\n",
    "!pip install torchdiffeq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YoaiL13zlkzP"
   },
   "source": [
    "### Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fwP58RjFlOLk"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "mnist_train = torchvision.datasets.MNIST(root='data',train=True,download=True, transform=transform)\n",
    "mnist_test = torchvision.datasets.MNIST(root='data',train=False,download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UCaCeRPwvI7f"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(mnist_train, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZA53Ai4Q3xEd"
   },
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q2g6N-gQ3wGf"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(model, criterion = loss_fn, epochs=10, device=torch.device('cuda'),\n",
    "              train_loader=train_loader, test_loader=test_loader, flatten_input=False):\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    model = model.to(device)\n",
    "\n",
    "    accs = []\n",
    "    times = []\n",
    "    for epoch in range(epochs):\n",
    "        t1 = time()\n",
    "        model.train() # Training\n",
    "        for i, (X,y) in progressbar(enumerate(train_loader)):\n",
    "            if flatten_input: # Use for feed-forward networks\n",
    "                X = X.view(-1, 1, 784) # flatten spatial dim\n",
    "            X = X.to(device) # put on GPU\n",
    "\n",
    "            # y = F.one_hot(y, num_classes=10) # convert labels to one-hot encoding\n",
    "            y = y.to(device)\n",
    "\n",
    "            model.zero_grad() # zero gradients\n",
    "\n",
    "            out = model.forward(X) # forward pass\n",
    "\n",
    "            loss = criterion(out, y) # compute loss\n",
    "            loss.backward() # backpropagate\n",
    "            optimizer.step() # update model\n",
    "\n",
    "        model.eval() # Evaluation\n",
    "        n_correct=0\n",
    "        n = 0\n",
    "        for i, (X,y) in enumerate(test_loader):\n",
    "            if flatten_input: # Use for feed-forward networks\n",
    "                X = X.view(-1, 1, 784) # flatten spatial dim\n",
    "            X = X.to(device) # put on GPU\n",
    "            y = y.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                out = model.forward(X) # forward pass\n",
    "\n",
    "            n_correct += torch.sum(torch.argmax(out,dim=-1).view(-1) == y)\n",
    "            n += len(y)\n",
    "        acc = (1.*n_correct)/(1.*n) # record accuracy\n",
    "        t2 = time() - t1 # record time\n",
    "\n",
    "        accs.append(acc)\n",
    "        times.append(t2)\n",
    "\n",
    "        print('Epoch {} error: {:.4f}'.format(epoch+1, 1-acc))\n",
    "        print('Epoch {} time : {:.4f}'.format(epoch+1, t2))\n",
    "        print()\n",
    "        \n",
    "    return(accs, times)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bnCatjwSH0u8"
   },
   "source": [
    "#### 1-layer MLP (feed-forward neural net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "anlf3JiMmRsA"
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim=28**2, hidden_dim=64, output_dim=10):\n",
    "        super(MLP, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bn = torch.nn.BatchNorm1d(1) # batch normalization\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn(self.fc1(x)))\n",
    "        out = self.fc2(out)\n",
    "        return(out.squeeze(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2AOgEUw4f2jU"
   },
   "source": [
    "#### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E4KzDdN6f5fA"
   },
   "outputs": [],
   "source": [
    "# Adapted from https://github.com/rtqichen/torchdiffeq/blob/master/examples/odenet_mnist.py\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride)\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride)\n",
    "\n",
    "def norm(dim):\n",
    "    '''Group normalization'''\n",
    "    return nn.GroupNorm(min(32, dim), dim)\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Flatten, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        shape = torch.prod(torch.tensor(x.shape[1:])).item()\n",
    "        return x.view(-1, shape)\n",
    "\n",
    "class ResBlock(nn.Module):  \n",
    "    '''Implements the residual block described in 'Identity Mappings in Deep\n",
    "        Residual Networks, by Kaiming He et al.'''\n",
    "    def __init__(self, in_planes, out_planes, stride=1, downsample=None):\n",
    "        super(ResBlock, self).__init__()\n",
    "\n",
    "        self.norm1 = norm(in_planes)\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride)\n",
    "        self.norm2 = norm(out_planes)\n",
    "        self.conv2 = nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        out = F.relu(self.norm1(x))\n",
    "        out = self.conv1(out)\n",
    "        out = F.relu(self.norm2(out))\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        return out + shortcut\n",
    "\n",
    "# Layers to downsample input before going to residual blocks or ODE block\n",
    "downsampling_layers = [\n",
    "            nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, stride=1),\n",
    "            norm(64), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=4, stride=2),\n",
    "            norm(64), nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=4, stride=2),\n",
    "        ]\n",
    "\n",
    "# Fully connected layers (after doing residual blocks or ODE block)\n",
    "fc_layers = [norm(64), nn.ReLU(inplace=True), nn.AdaptiveAvgPool2d((1, 1)), Flatten(), nn.Linear(64, 10)]\n",
    "\n",
    "# Now create model\n",
    "res_layers = [ResBlock(64,64) for _ in range(6)]\n",
    "\n",
    "def make_resnet():\n",
    "    return nn.Sequential(*downsampling_layers, *res_layers, *fc_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1U95TIEQ_D72"
   },
   "source": [
    "#### Neural ODE (custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tr-VhwmVrnSp"
   },
   "outputs": [],
   "source": [
    "def rk(fun, t_span, y0, h):\n",
    "    '''Runge-Kutta 4th order method\n",
    "        Args: - fun is derivative\n",
    "              - t_span is tuple of start and end time\n",
    "              - y0 is initial condition\n",
    "              - h is step size (fixed in this case)'''\n",
    "    weights = torch.tensor([1/6, 1/3, 1/3, 1/6])[:,None,None,None,None].to(y0.device)\n",
    "    n_steps = int((t_span[1]-t_span[0])/h)\n",
    "    y = y0 # set state to initial state\n",
    "    t = t_span[0]\n",
    "    for _ in range(n_steps):\n",
    "        k1 = h * fun(t     , y)\n",
    "        k2 = h * fun(t+.5*h, y+.5*k1)\n",
    "        k3 = h * fun(t+.5*h, y+.5*k2)\n",
    "        k4 = h * fun(t+   h, y+   k3)\n",
    "        t = t + h\n",
    "        y = y + torch.sum(weights * torch.stack([k1,k2,k3,k4], dim=0), dim=0)\n",
    "    return y\n",
    "\n",
    "class ODE_block(ResBlock):\n",
    "\n",
    "    def __init__(self, planes=64):\n",
    "        super(ODE_block, self).__init__(planes,planes)\n",
    "\n",
    "        self.t_span = nn.Parameter(torch.tensor([0.,2.], requires_grad=True))\n",
    "\n",
    "    def ode(self, t, x): \n",
    "        '''Function representing the ODE to be solved. It is almost the same as \n",
    "            the forward pass in the residual block, but we do not add the \n",
    "            shortcut connection in this case.'''\n",
    "        out = F.relu(self.norm1(x))\n",
    "        out = self.conv1(out)\n",
    "        out = F.relu(self.norm2(out))\n",
    "        out = self.conv2(out)\n",
    "        return out\n",
    "\n",
    "    def forward(self, y):\n",
    "        '''Forward pass using ODE solver'''\n",
    "        return rk(fun=self.ode, t_span=self.t_span, h=.5, y0=y) \n",
    "\n",
    "def make_odenet():\n",
    "    return nn.Sequential(*downsampling_layers, ODE_block(), *fc_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fxD6sWW40_V5"
   },
   "source": [
    "#### Neural ODE (from torchdiffeq package)\n",
    "Used to compare custom ODE with authors' adjoint implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MhlZQUkp1D4f"
   },
   "outputs": [],
   "source": [
    "from torchdiffeq import odeint, odeint_adjoint\n",
    "\n",
    "class ODE_Func(nn.Module):  \n",
    "    '''Implements the residual block described in 'Identity Mappings in Deep\n",
    "        Residual Networks, by Kaiming He et al.'''\n",
    "    def __init__(self, dim, stride=1, downsample=None):\n",
    "        super(ODE_Func, self).__init__()\n",
    "\n",
    "        self.norm1 = norm(dim)\n",
    "        self.conv1 = nn.Conv2d(dim, dim, kernel_size=3, stride=stride)\n",
    "        self.norm2 = norm(dim)\n",
    "        self.conv2 = nn.Conv2d(dim, dim, kernel_size=1, stride=stride, padding=1)\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        out = F.relu(self.norm1(x))\n",
    "        out = self.conv1(out)\n",
    "        out = F.relu(self.norm2(out))\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ODE_block_adjoint(ODE_block):\n",
    "    def __init__(self, planes=64):\n",
    "        super(ODE_block_adjoint, self).__init__(planes)\n",
    "        self.t_span = nn.Parameter(torch.tensor([0.,2.], requires_grad=True))\n",
    "        self.t = torch.tensor([0.,.5,1.,1.5,2.])\n",
    "        self.fun = ODE_Func(planes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = odeint_adjoint(self.fun, x, self.t, method='rk4')\n",
    "        return out[1]\n",
    "\n",
    "def make_odenet_adjoint():\n",
    "    return nn.Sequential(*downsampling_layers, ODE_block_adjoint(), *fc_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iPfyReu84kBa"
   },
   "source": [
    "### Run trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 358
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "6oY2Ds5raKy5",
    "outputId": "a1b1e2ea-a6dd-4cfe-92e5-659dbf078fcc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                        #                       | 1874 Elapsed Time: 0:01:43\n",
      "| | #                                                 | 3 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 error: 0.0082\n",
      "Epoch 1 time : 107.0992\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                                #               | 1874 Elapsed Time: 0:01:42\n",
      "\\ | #                                                 | 3 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 error: 0.0073\n",
      "Epoch 2 time : 106.2570\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                              #                 | 1874 Elapsed Time: 0:01:39\n",
      "\\ | #                                                 | 3 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 error: 0.0095\n",
      "Epoch 3 time : 102.8515\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                                       #        | 1874 Elapsed Time: 0:01:39\n",
      "| | #                                                 | 3 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 error: 0.0078\n",
      "Epoch 4 time : 103.8910\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "| |                             #                  | 1874 Elapsed Time: 0:01:42\n",
      "| | #                                                 | 3 Elapsed Time: 0:00:00"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 error: 0.0062\n",
      "Epoch 5 time : 106.6296\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\ |                              #                  | 773 Elapsed Time: 0:00:42"
     ]
    }
   ],
   "source": [
    "epochs_per_trial = 20\n",
    "n_trials = 3\n",
    "\n",
    "res = []\n",
    "\n",
    "for trial in range(n_trials):\n",
    "\n",
    "    mlp = MLP()\n",
    "    accs, times = train(model=mlp, device='cuda', epochs=epochs_per_trial, flatten_input=True)\n",
    "    res.append({'model':'mlp', 'accuracy':torch.tensor(accs).numpy(), 'time':times})\n",
    "\n",
    "    resnet = make_resnet()\n",
    "    accs, times = train(resnet, epochs=epochs_per_trial)\n",
    "    res.append({'model':'resnet', 'accuracy':torch.tensor(accs).numpy(), 'time':times})\n",
    "\n",
    "    ode_net = make_odenet()\n",
    "    accs, times = train(ode_net, epochs=epochs_per_trial)\n",
    "    res.append({'model':'rk-net', 'accuracy':torch.tensor(accs).numpy(), 'time':times})\n",
    "\n",
    "    odenet_adjoint = make_odenet_adjoint()\n",
    "    accs, times = train(odenet_adjoint, epochs=epochs_per_trial)\n",
    "    res.append({'model':'ode-net', 'accuracy':torch.tensor(accs).numpy(), 'time':times})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MPIaUmlpAjeC"
   },
   "source": [
    "#### (optional) write results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OtbDS5j0AKtC"
   },
   "outputs": [],
   "source": [
    "# # write results to file (optional)\n",
    "# from google.colab import files\n",
    "# import pickle\n",
    "\n",
    "# fname = 'results.pkl'\n",
    "# pickle.dump(res, open(fname, 'wb'))\n",
    "# files.download(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B3iYHYa1Ab9R"
   },
   "source": [
    "#### Print out results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_9qZHpmEALbN"
   },
   "outputs": [],
   "source": [
    "res = pd.DataFrame(res)\n",
    "\n",
    "acc_df = pd.DataFrame(res['accuracy'].values.tolist()).T\n",
    "time_df = pd.DataFrame(res['time'].values.tolist()).T\n",
    "\n",
    "acc_df.columns = res.model.values\n",
    "time_df.columns = res.model.values\n",
    "\n",
    "print('ERROR')\n",
    "print('Minimum values:')\n",
    "print(1-acc_df.max().groupby(level=0).mean())\n",
    "print()\n",
    "\n",
    "print('std:')\n",
    "print(acc_df.max().groupby(level=0).std())\n",
    "\n",
    "print('\\n\\nTIME')\n",
    "print('Mean values:')\n",
    "print(time_df.sum().groupby(level=0).mean())\n",
    "print()\n",
    "\n",
    "print('std:')\n",
    "print(time_df.sum().groupby(level=0).std())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "YoaiL13zlkzP",
    "ZA53Ai4Q3xEd",
    "RZ5t5Wpa3mZd",
    "2AOgEUw4f2jU"
   ],
   "name": "mnist_trials.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
